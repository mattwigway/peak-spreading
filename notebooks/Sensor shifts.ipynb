{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8509d636-cf32-4f1b-af1a-d9716ac35997",
   "metadata": {},
   "source": [
    "# Sensor shifts\n",
    "\n",
    "Make sure sensor locations are stable over time. Most are, but some are not. Write out a file with those that are not so we can drop them.\n",
    "\n",
    "TODO one file from d03 is empty - but shouldn't matter since it's the last one in 2015, and there's a new one in March 2016, and we're not using any data from pre-March 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed348e0-967e-4fa1-904b-5eac12189886",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, DataFramesMeta, Logging, ProgressMeter, Geodesy, Dates, StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834cc5b6-580a-49fa-bd64-8d4895075920",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = filter(readdir(\"../data/meta/\")) do fn\n",
    "    !isnothing(match(r\"^d.*_text_meta_.*\\.txt\", fn))\n",
    "end\n",
    "nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d62d09-59f9-478f-b0a4-7e4980d0dc87",
   "metadata": {},
   "source": [
    "## Figure out which dates to read\n",
    "\n",
    "We want to read all metadata files from 2016 or later, and the last file before 2016-01-01, so we have valid metadata for the entire analysis period. We want to stop reading at 2022-08-19, in case people have newer metadata that would make some sensors drop out.\n",
    "\n",
    "(Why August 19 instead of 18? There were several sensors that moved/changed the very next day after our analysis window, and it's possible that they would have had some effects of whatever caused this change pre-August 19. Also, that's what the metadata we downloaded at the same time as we downloaded the data showed.)\n",
    "\n",
    "The PeMS site lists some earlier metadata files as extending into this period as well, but I think that's an error- metadata files seem to contain all sensors, so each should supersede the last. I have an email into PeMS to confirm. For now we ignore those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98804d15-d583-4533-b56e-c731ab264461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_by_district = Dict{String, Vector{Date}}()\n",
    "\n",
    "for file in files\n",
    "    parsed = match(r\"^d0?([1-9][0-9]?)_text_meta_([0-9]{4})_([0-9]{2})_([0-9]{2}).txt\", file)\n",
    "    if !haskey(dates_by_district, parsed[1])\n",
    "        dates_by_district[parsed[1]] = []\n",
    "    end\n",
    "    date = Date(parse(Int64, parsed[2]), parse(Int64, parsed[3]), parse(Int64, parsed[4]))\n",
    "    push!(dates_by_district[parsed[1]], date)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497cdb61-b5c4-43a5-8a1c-6ffce77d2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_retain_by_district = Dict{String, Set{Date}}()\n",
    "\n",
    "for (district, dates) in pairs(dates_by_district)\n",
    "    # retain the file before 2016-01-01 and all after\n",
    "    last_date_before_2016 = Date(1970, 1, 1)\n",
    "    \n",
    "    for date in dates\n",
    "        if date <= Date(2016, 1, 1) && date > last_date_before_2016\n",
    "            last_date_before_2016 = date\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    dates_to_retain_by_district[district] = Set(collect(filter(d -> d >= last_date_before_2016, dates)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241ed88-0f8f-41cb-8cd8-ed6cd8777e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta = vcat(skipmissing(map(files) do file\n",
    "        parsed = match(r\"^d0?([1-9][0-9]?)_text_meta_([0-9]{4})_([0-9]{2})_([0-9]{2}).txt\", file)\n",
    "        date = Date(parse(Int64, parsed[2]), parse(Int64, parsed[3]), parse(Int64, parsed[4]))\n",
    "\n",
    "        if !in(date, dates_to_retain_by_district[parsed[1]])\n",
    "            return missing\n",
    "        else\n",
    "            data = CSV.read(joinpath(\"../data/meta\", file), DataFrame;\n",
    "                types=Dict(:Longitude=>Union{Missing,Float64}), validate=false)\n",
    "            if ncol(data) == 0 && nrow(data) == 0\n",
    "                @warn \"file $file is empty, skipping\"\n",
    "                return missing\n",
    "            end\n",
    "            select!(data, [:ID, :Fwy, :Dir, :Latitude, :Longitude, :District, :Lanes, :County])\n",
    "            data[!, :date] .= date\n",
    "            return data\n",
    "        end\n",
    "    end)...)\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f820b9-8650-4ab5-958d-168e3a0baffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_meta = all_meta[all_meta.date .<= Date(2022, 8, 19), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9ba2a-a1d2-4692-a547-7e6bfd1cfe0e",
   "metadata": {},
   "source": [
    "## Compute station-level statistics\n",
    "\n",
    "Make sure that freeway, direction, and number of lanes are stable, and that location did not shift by more than 100 meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683f4ff-771b-459d-a7ad-07ff6d5dfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "function max_shift(lats, lons)\n",
    "    @assert length(lats) == length(lons)\n",
    "    max_shift = 0\n",
    "    for i in 1:length(lats)\n",
    "        if ismissing(lats[i]) && ismissing(lons[i]) continue end\n",
    "        pos_i = LLA(lats[i], lons[i], 0)\n",
    "        for j in 1:length(lons)\n",
    "            if ismissing(lats[j]) && ismissing(lons[j]) continue end\n",
    "            pos_j = LLA(lats[j], lons[j], 0)\n",
    "            dist = euclidean_distance(pos_i, pos_j)\n",
    "            if dist > max_shift\n",
    "                max_shift = dist\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return max_shift\n",
    "end\n",
    "\n",
    "last_nonmissing(x) = first(skipmissing(reverse(x)))\n",
    "\n",
    "function last_nonmissing(lats, lons)\n",
    "    for i in length(lats):-1:1\n",
    "        if !ismissing(lats[i]) && !ismissing(lons[i])\n",
    "            return (Latitude=lats[i], Longitude=lons[i])\n",
    "        end\n",
    "    end\n",
    "    return (Latitude=missing, Longitude=missing)\n",
    "end\n",
    "    \n",
    "station_stats = combine(groupby(all_meta, :ID),\n",
    "    :Fwy => (x -> length(unique(x)) == 1) => :fwy_stable,\n",
    "    :Dir => (x -> length(unique(x)) == 1) => :dir_stable,\n",
    "    :Lanes => (x -> length(unique(x)) == 1) => :lanes_stable,\n",
    "    [:Latitude, :Longitude] => max_shift => :max_shift_meters,\n",
    "    # save representative values so we have them for all sensors\n",
    "    # this file will be used to identify the lat/lons of sensors in the final dataset,\n",
    "    # some sensors may not appear in one particular metadata file, so use the combination\n",
    "    [:Latitude, :Longitude] => last_nonmissing => [:Latitude, :Longitude],\n",
    "    :Fwy => last_nonmissing => :Fwy,\n",
    "    :Dir => last_nonmissing => :Dir,\n",
    "    :District => last_nonmissing => :District,\n",
    "    :Lanes => last_nonmissing => :Lanes,\n",
    "    :County => last_nonmissing => :County\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220d533-5339-44d7-8c90-1cfc68850447",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(station_stats.fwy_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba574b5-8541-47d5-8e7f-f525ad74acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(station_stats.dir_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d155f81-99e8-444d-9962-1e536211ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(station_stats.lanes_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e3cdd-d8cf-43df-9cab-0b2fb3882cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(station_stats.max_shift_meters .< 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10a168-7cba-43ab-8acd-0821f1b51ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(\n",
    "    station_stats.fwy_stable .&\n",
    "    station_stats.dir_stable .&\n",
    "    station_stats.lanes_stable .&\n",
    "    (station_stats.max_shift_meters .< 100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd368e3-8ee2-40e6-9df6-86d058ff02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_stats.ID[ismissing.(station_stats.Latitude)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2081d1-206e-4e7c-bce6-fef847eb6c6d",
   "metadata": {},
   "source": [
    "## Extract metadata for good sensors\n",
    "\n",
    "This will be used to filter the sensor data to exclude the sensors that are unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfce0b9-1a71-444c-9f13-2e00ae56b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sensor_meta = station_stats[station_stats.fwy_stable .&\n",
    "    station_stats.dir_stable .&\n",
    "    station_stats.lanes_stable .&\n",
    "    (station_stats.max_shift_meters .< 100) .&\n",
    "    (.!ismissing.(station_stats.Latitude)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd4de3-d709-4eea-9f6f-d34c9c38ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"../data/good_sensors.csv\", good_sensor_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f5e8a-9df2-485a-9c47-431e69edea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta[all_meta.ID .== 415657 .&& all_meta.date .> Date(2022,1,1), [:Lanes, :Dir, ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia threads project 1.8.5",
   "language": "julia",
   "name": "julia-threads-project-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
